{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys\n",
    "from skimage import feature\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interfacing Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"preview\")\n",
    "vc = cv2.VideoCapture(0)\n",
    "\n",
    "if vc.isOpened(): # try to get the first frame\n",
    "    rval, frame = vc.read()\n",
    "else:\n",
    "    rval = False\n",
    "\n",
    "while rval:\n",
    "    cv2.imshow(\"preview\", frame)\n",
    "    rval, frame = vc.read()\n",
    "    key = cv2.waitKey(20)\n",
    "    if key == 27: # exit on ESC\n",
    "        break\n",
    "cv2.destroyWindow(\"preview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection (Haar Feature Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "    # Draw a rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        if (w>120 or h>120):\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Log of Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "count=100\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "    # Draw a rectangle around the faces\n",
    "    count+=1\n",
    "    for (x, y, w, h) in faces:\n",
    "        if (w>120 or h>120):\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), thickness=4)\n",
    "            #Save just the rectangle faces in SubRecFaces\n",
    "            sub_face = frame[y:y+h, x:x+w]\n",
    "            cv2.imwrite('C:/Users/user/training/focused/fface'+str(count)+\".jpg\", sub_face)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction of Faces (Local Binary Pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\ame\\lib\\site-packages\\ipykernel_launcher.py:32: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "from scipy.misc import imread\n",
    "\n",
    " \n",
    "from skimage import feature\n",
    "import numpy as np\n",
    " \n",
    "class LocalBinaryPatterns:\n",
    "    def __init__(self, numPoints, radius):\n",
    "        # store the number of points and radius\n",
    "        self.numPoints = numPoints\n",
    "        self.radius = radius\n",
    "\n",
    "    def describe(self, image, eps=1e-7):\n",
    "        # compute the Local Binary Pattern representation\n",
    "        # of the image, and then use the LBP representation\n",
    "        # to build the histogram of patterns\n",
    "        lbp = feature.local_binary_pattern(image, self.numPoints,self.radius, method=\"uniform\")\n",
    "        (hist, _) = np.histogram(lbp.ravel(),bins=np.arange(0, self.numPoints + 3),range=(0, self.numPoints + 2))\n",
    "\n",
    "        # normalize the histogram\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + eps)\n",
    "\n",
    "        # return the histogram of Local Binary Patterns\n",
    "        return hist\n",
    "desc = LocalBinaryPatterns(24, 8)\n",
    "im = imread(\"fface126.jpg\")\n",
    "gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "lbp = desc.describe(gray)\n",
    "plt.hist(lbp, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the local binary patterns descriptor along with\n",
    "# the data and label lists\n",
    "p=24\n",
    "r=8\n",
    "desc = LocalBinaryPatterns(p, r)\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the training images\n",
    "for cls in os.listdir(\"C:/Users/user/training\"):\n",
    "    clspath = os.path.join(\"C:/Users/user/training\",cls)\n",
    "    for file in os.listdir(clspath):\n",
    "        # load the image, convert it to grayscale, and describe it\n",
    "        imagePath = os.path.join(clspath,file)\n",
    "        image = cv2.imread(imagePath)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        hist = desc.describe(gray)\n",
    "\n",
    "        # extract the label from the image path, then update the\n",
    "        # label and data lists\n",
    "        labels.append(cls)\n",
    "        data.append(hist)\n",
    " \n",
    "#Train a Linear SVM on the data\n",
    "model1 = LinearSVC(C=500.0)\n",
    "model1.fit(data, labels)\n",
    "pickle.dump(model1,open(\"C:/Users/user/modelling.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in os.listdir(\"C:/Users/user/test\"):\n",
    "    clspath = os.path.join(\"C:/Users/user/test\",cls)\n",
    "    for file in os.listdir(clspath):\n",
    "        # load the image, convert it to grayscale, describe it,\n",
    "        # and classify it\n",
    "        imagePath = os.path.join(clspath,file)\n",
    "        image = cv2.imread(imagePath)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        hist = desc.describe(gray)\n",
    "        prediction = model1.predict(hist.reshape(1, -1))\n",
    "\n",
    "        # display the image and the prediction\n",
    "        cv2.putText(image, prediction[0], (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1.0, (0, 0, 255), 3)\n",
    "        cv2.imshow(\"Image\", image)\n",
    "        cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Time Emotion Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "cv2.namedWindow(\"preview\")\n",
    "vc = cv2.VideoCapture(0)\n",
    "model = pickle.load(open(\"C:/Users/user/modelling.pkl\", 'rb'))\n",
    "desc = LocalBinaryPatterns(24, 8)\n",
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640,480))\n",
    "timestamps = []\n",
    "status = []\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "    # Draw a rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        if (w>120 or h>120):\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), thickness=4)\n",
    "            #Save just the rectangle faces in SubRecFaces\n",
    "            sub_face = frame[y:y+h, x:x+w]\n",
    "            gray = cv2.cvtColor(sub_face, cv2.COLOR_BGR2GRAY)\n",
    "            hist = desc.describe(gray)\n",
    "            prediction = model.predict(hist.reshape(1, -1))\n",
    "\n",
    "        # display the image and the prediction\n",
    "            cv2.putText(frame, prediction[0], (x, y), cv2.FONT_HERSHEY_COMPLEX, 1.5, (0, 0, 255),3, cv2.LINE_AA)\n",
    "            timestamps.append(datetime.datetime.now().time())\n",
    "            status.append(prediction[0])\n",
    "\n",
    "    cv2.imshow(\"preview\", frame)\n",
    "    out.write(frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27: # exit on ESC\n",
    "        break\n",
    "video_capture.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = []\n",
    "for i in range(len(status)):\n",
    "    if (status[i]=='notfocused' or status[i]=='moderatelyfocused'):\n",
    "        state.append(0)\n",
    "    else:\n",
    "        state.append(1)\n",
    "d = {'Time Stamp':timestamps,'Status':state}\n",
    "df = pd.DataFrame(d)\n",
    "df.to_csv('trackeddata.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
